{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06e7fa4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/Diss/lib/python3.7/site-packages/ipykernel_launcher.py:3: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "import tensorflow\n",
    "import kerastuner \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60c5313d-d85d-4271-9895-54162f8cf2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import (\n",
    "    Conv2D,\n",
    "    Dense,\n",
    "    Dropout,\n",
    "    Flatten,\n",
    "    MaxPooling2D, \n",
    "    BatchNormalization\n",
    ")\n",
    "\n",
    "import random\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0972533",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "iris = datasets.load_breast_cancer()\n",
    "X = iris.data[:, :]  # we only take the first two features.\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71322bb9-cd3a-4709-8fc3-894cfbfab0a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5fbf2e65-5484-4944-9cb6-990c3a09f7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29a7a0a4-3119-4abc-8daa-56d20e447f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing StandardScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#creating object\n",
    "sc = StandardScaler()\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_test = sc.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "902d8474-2778-4af7-b935-052cb29c9973",
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = ['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce043ae9-86e6-4cef-b8a2-097385df69b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    \n",
    "    model = keras.Sequential()\n",
    "    \n",
    "    for i in range(hp.Choice('num_layers', [1,2,3])):\n",
    "        model.add(keras.layers.Dense(units=hp.Choice('units_' + str(i+ 1),[8, 16, 32, 64, 128]), \\\n",
    "                                     kernel_initializer = hp.Choice('kernel_init', ['glorot_uniform']), \\\n",
    "                                     activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(rate=hp.Choice('dropout_'+ str(i),[0.0,0.1,0.2, 0.5])))\n",
    "        \n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer=keras.optimizers.Adam(hp.Choice('learning_rate', [1.0, 0.1, 0.01, 0.001])),\\\n",
    "                  loss='binary_crossentropy',metrics=METRICS)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83466ab8-0217-4348-b0f9-056b49697185",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "\n",
    "class MyTuner(kerastuner.tuners.RandomSearch):\n",
    "    def run_trial(self, trial, *args, **kwargs):\n",
    "        \n",
    "        # You can add additional HyperParameters for preprocessing and custom training loops\n",
    "        # via overriding `run_trial`\n",
    "        kwargs['batch_size'] = trial.hyperparameters.Choice('batch_size', [8, 16, 64, 128])\n",
    "        super(MyTuner, self).run_trial(trial, *args, **kwargs)\n",
    "\n",
    "# Uses same arguments as the Random Search Tuner.\n",
    "tuner = MyTuner(\n",
    "    build_model,\n",
    "    objective=kerastuner.Objective(\"val_accuracy\", direction=\"max\"),\n",
    "    max_trials=5,\n",
    "    executions_per_trial=10,\n",
    "    directory='Tuning',\n",
    "    project_name= str(time.time()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1848408c-3d06-4c81-992f-af6a1756932c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 5\n",
      "num_layers (Choice)\n",
      "{'default': 1, 'conditions': [], 'values': [1, 2, 3], 'ordered': True}\n",
      "units_1 (Choice)\n",
      "{'default': 8, 'conditions': [], 'values': [8, 16, 32, 64, 128], 'ordered': True}\n",
      "kernel_init (Choice)\n",
      "{'default': 'glorot_uniform', 'conditions': [], 'values': ['glorot_uniform'], 'ordered': False}\n",
      "dropout_0 (Choice)\n",
      "{'default': 0.0, 'conditions': [], 'values': [0.0, 0.1, 0.2, 0.5], 'ordered': True}\n",
      "learning_rate (Choice)\n",
      "{'default': 1.0, 'conditions': [], 'values': [1.0, 0.1, 0.01, 0.001], 'ordered': True}\n"
     ]
    }
   ],
   "source": [
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ded7e6de-d0d5-4586-bb37-1cc17327180d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1 Complete [00h 00m 28s]\n",
      "val_accuracy: 0.9499999761581421\n",
      "\n",
      "Best val_accuracy So Far: 0.9499999761581421\n",
      "Total elapsed time: 00h 00m 28s\n",
      "\n",
      "Search: Running Trial #2\n",
      "\n",
      "Hyperparameter    |Value             |Best Value So Far \n",
      "num_layers        |1                 |3                 \n",
      "units_1           |16                |32                \n",
      "kernel_init       |glorot_uniform    |glorot_uniform    \n",
      "dropout_0         |0.5               |0.1               \n",
      "learning_rate     |0.01              |1                 \n",
      "batch_size        |8                 |8                 \n",
      "units_2           |64                |8                 \n",
      "dropout_1         |0                 |0                 \n",
      "units_3           |16                |8                 \n",
      "dropout_2         |0                 |0                 \n",
      "\n",
      "Epoch 1/15\n",
      "43/43 [==============================] - 1s 6ms/step - loss: 0.5882 - accuracy: 0.6873 - val_loss: 0.1451 - val_accuracy: 0.9535\n",
      "Epoch 2/15\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.2293 - accuracy: 0.9080 - val_loss: 0.1367 - val_accuracy: 0.9651\n",
      "Epoch 3/15\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.1200 - accuracy: 0.9671 - val_loss: 0.1376 - val_accuracy: 0.9651\n",
      "Epoch 4/15\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.1536 - accuracy: 0.9434 - val_loss: 0.1268 - val_accuracy: 0.9535\n",
      "Epoch 5/15\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.3056 - accuracy: 0.8929 - val_loss: 0.1230 - val_accuracy: 0.9651\n",
      "Epoch 6/15\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.1699 - accuracy: 0.9458 - val_loss: 0.1215 - val_accuracy: 0.9419\n",
      "Epoch 7/15\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.1045 - accuracy: 0.9548 - val_loss: 0.1139 - val_accuracy: 0.9651\n",
      "Epoch 8/15\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.1559 - accuracy: 0.9514 - val_loss: 0.1310 - val_accuracy: 0.9535\n",
      "Epoch 9/15\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.1103 - accuracy: 0.9743 - val_loss: 0.1414 - val_accuracy: 0.9419\n",
      "Epoch 10/15\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.1445 - accuracy: 0.9537 - val_loss: 0.1352 - val_accuracy: 0.9419\n",
      "Epoch 11/15\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.1230 - accuracy: 0.9548 - val_loss: 0.1309 - val_accuracy: 0.9651\n",
      "Epoch 12/15\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.1554 - accuracy: 0.9270 - val_loss: 0.1189 - val_accuracy: 0.9535\n",
      "Epoch 13/15\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.2799 - accuracy: 0.9211 - val_loss: 0.1114 - val_accuracy: 0.9535\n",
      "Epoch 14/15\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.1169 - accuracy: 0.9687 - val_loss: 0.1076 - val_accuracy: 0.9535\n",
      "Epoch 15/15\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.1339 - accuracy: 0.9406 - val_loss: 0.1054 - val_accuracy: 0.9651\n",
      "Epoch 1/15\n",
      " 1/43 [..............................] - ETA: 20s - loss: 1.4637 - accuracy: 0.3750"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-f4f6e29e86eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m tuner.search(x_train, y_train,\\\n\u001b[1;32m      2\u001b[0m              \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m              validation_split = 0.2)\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/envs/Diss/lib/python3.7/site-packages/keras_tuner/engine/base_tuner.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_trial_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_trial_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_search_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-21e20b5827dd>\u001b[0m in \u001b[0;36mrun_trial\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;31m# via overriding `run_trial`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'batch_size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mChoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'batch_size'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMyTuner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Uses same arguments as the Random Search Tuner.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/Diss/lib/python3.7/site-packages/keras_tuner/engine/multi_execution_tuner.py\u001b[0m in \u001b[0;36mrun_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0mcopied_fit_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"callbacks\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m             \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_and_fit_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopied_fit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_values\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moracle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirection\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"min\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/Diss/lib/python3.7/site-packages/keras_tuner/engine/tuner.py\u001b[0m in \u001b[0;36m_build_and_fit_model\u001b[0;34m(self, trial, fit_args, fit_kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \"\"\"\n\u001b[1;32m    146\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhypermodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/Diss/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/Diss/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/Diss/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/Diss/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/Diss/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/Diss/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_build_call_outputs\u001b[0;34m(self, result)\u001b[0m\n\u001b[1;32m   2164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2165\u001b[0m     \u001b[0;31m# Replace outputs with results, skipping over any 'None' values.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2166\u001b[0;31m     outputs_list = nest.flatten(\n\u001b[0m\u001b[1;32m   2167\u001b[0m         self._func_graph.structured_outputs, expand_composites=True)\n\u001b[1;32m   2168\u001b[0m     \u001b[0mj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tuner.search(x_train, y_train,\\\n",
    "             epochs=15,\\\n",
    "             validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4f03d9-ae14-417c-b227-38ca81f48d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the optimal hyperparameters\n",
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d16eb4c-5086-4743-8453-0e6c85783ebe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Build the model with the optimal hyperparameters and train it on the data for 50 epochs\n",
    "model = tuner.hypermodel.build(best_hps)\n",
    "history = model.fit(x_train, y_train, epochs=150, validation_split=0.2)\n",
    "\n",
    "val_acc_per_epoch = history.history['val_accuracy']\n",
    "best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\n",
    "print('Best epoch: %d' % (best_epoch,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379e2a42-d5e7-4f97-83bd-bb0c2e623e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "hypermodel = tuner.hypermodel.build(best_hps)\n",
    "\n",
    "# Retrain the model\n",
    "hypermodel.fit(x_train, y_train, epochs=best_epoch, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2ad6ae-94ab-41ca-9064-97e4819908d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_result = hypermodel.evaluate(x_test, y_test)\n",
    "print(\"[test loss, test accuracy]:\", eval_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5531fa9-2470-4f84-963a-7cc68f8f96d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "cm = confusion_matrix(y_test,hypermodel.predict(x_test) > 0.5)\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0a83b8-d3aa-46ae-a58e-1ccadadb468e",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = tuner.get_best_hyperparameters(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59a7790-b7f1-44b1-968a-5090bbaa1224",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_model[0].values)\n",
    "print(best_model[1].values)\n",
    "print(best_model[2].values)\n",
    "print(best_model[3].values)\n",
    "print(best_model[4].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a3fcf1-b8e5-4547-a2ab-523b53381151",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.plot(history.history['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d19417-b382-42d6-bdd5-379f13bb966f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4787d3c-f56c-4766-9a52-95955085c400",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    \n",
    "    model = keras.Sequential()\n",
    "    \n",
    "    for i in range(hp.Choice('num_layers', [1,2,3])):\n",
    "        model.add(keras.layers.Dense(units=hp.Choice('units_' + str(i+ 1),[8, 16, 32, 64, 128]), kernel_initializer = hp.Choice('kernel_init', ['glorot_uniform']), activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(rate=hp.Choice('dropout_'+ str(i),[0.0,0.1,0.2, 0.5])))\n",
    "        \n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer=keras.optimizers.Adam(hp.Choice('learning_rate', [1.0, 0.1, 0.01, 0.001])),loss='binary_crossentropy',metrics=METRICS)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3adf7577-bf52-426a-a91f-4cf998ae1621",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import kerastuner\n",
    "import numpy as np\n",
    "from sklearn import model_selection\n",
    "\n",
    "class CVTuner(kerastuner.engine.tuner.Tuner):\n",
    "    def run_trial(self, trial, x, y, batch_size=16, epochs=1):\n",
    "        cv = model_selection.KFold(3)\n",
    "        val_acc = []\n",
    "        for train_indices, test_indices in cv.split(x):\n",
    "            x_train, x_val = x[train_indices], x[test_indices]\n",
    "            y_train, y_val = y[train_indices], y[test_indices]\n",
    "            model = self.hypermodel.build(trial.hyperparameters)\n",
    "            model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_data = (x_val, y_val))\n",
    "            val_acc.append(model.evaluate(x_val, y_val)[1])\n",
    "    \n",
    "        self.oracle.update_trial(trial.trial_id, {'val_accuracy': np.mean(val_acc)})\n",
    "        self.save_model(trial.trial_id, model)\n",
    "\n",
    "tuner = CVTuner(\n",
    "  hypermodel=build_model,\n",
    "  oracle=kerastuner.oracles.BayesianOptimization(\n",
    "    objective=kerastuner.Objective(\"val_accuracy\", direction=\"max\"),\n",
    "    max_trials=25), \\\n",
    "    directory='Tuning',\\\n",
    "    project_name= str(time.time()))\n",
    "\n",
    "\n",
    "tuner.search(x_train, y_train,\\\n",
    "             epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c77aee-e215-4de2-be4a-17353c1cedbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the optimal hyperparameters\n",
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362d35f3-e8fc-4428-8476-947c009b0a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.get_best_hyperparameters(num_trials=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c94f990-3e5e-4074-b3a2-414c0dd95905",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Build the model with the optimal hyperparameters and train it on the data for 50 epochs\n",
    "model = tuner.hypermodel.build(best_hps)\n",
    "history = model.fit(x_train, y_train, epochs=150, validation_split=0.2)\n",
    "\n",
    "val_acc_per_epoch = history.history['val_accuracy']\n",
    "best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\n",
    "print('Best epoch: %d' % (best_epoch,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f0ffd2-27c8-4f0b-8cd9-a039755e4d58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hypermodel = tuner.hypermodel.build(best_hps)\n",
    "\n",
    "# Retrain the model\n",
    "hypermodel.fit(x_train, y_train, epochs=best_epoch, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82c2e13-b592-4e07-b340-8df257f77d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_result = hypermodel.evaluate(x_test, y_test)\n",
    "print(\"[test loss, test accuracy]:\", eval_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a82895b-8216-49e2-9e19-e34e9f8dd80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "cm = confusion_matrix(y_test,hypermodel.predict(x_test) > 0.5)\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4b5719-bf11-4aa6-b5c9-440ff8c1f789",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = tuner.get_best_hyperparameters(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498ae6ee-edd1-47ab-b464-0891d27a3ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_model[0].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc85b01-6a98-4e84-a7c1-9e64047cc1dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
